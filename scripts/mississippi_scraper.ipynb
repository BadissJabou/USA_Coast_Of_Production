{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 13:20:48,201 - ERROR - Error processing https://www.agecon.msstate.edu/whatwedo/budgets/docs/26/MSUFOR26.pdf: [Errno 13] Permission denied: 'C:\\\\Users\\\\pc\\\\AppData\\\\Local\\\\Temp\\\\tmpziyvh94o.pdf'\n",
      "2025-10-24 13:20:53,075 - ERROR - Error processing https://www.agecon.msstate.edu/whatwedo/budgets/docs/25/MSUFOR25_FINAL.pdf: [Errno 13] Permission denied: 'C:\\\\Users\\\\pc\\\\AppData\\\\Local\\\\Temp\\\\tmph_tec7sd.pdf'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'AMOUNT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AMOUNT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1e5b211fd2ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecent_links\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0myear_from_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;31m# First batch uses title, others use URL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_pdf_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear_from_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear_from_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"part{i+1}.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Processed part {i+1}, unique items: {data['ITEM'].unique() if not data.empty else 'None'}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1e5b211fd2ea>\u001b[0m in \u001b[0;36mprocess_pdf_batch\u001b[1;34m(pdf_links, year_from_url)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# Clean data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     \u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AMOUNT'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AMOUNT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m     \u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ppi,'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2023'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDATA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pc\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pc\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AMOUNT'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pypdf import PdfReader  # Updated from PyPDF2\n",
    "import tempfile\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def transform_year(year):\n",
    "    \"\"\"\n",
    "    Transform the date as 2022 to 2022/2023\n",
    "    \"\"\"\n",
    "    year = int(year)\n",
    "    return f\"{year}/{year+1}\"\n",
    "\n",
    "def strip_characters(input_string, characters_to_remove):\n",
    "    translation_table = str.maketrans(\"\", \"\", characters_to_remove)\n",
    "    stripped_string = input_string.translate(translation_table)\n",
    "    return stripped_string\n",
    "\n",
    "def last_uppercase_position(text):\n",
    "    match = re.search(r'[A-Z]', text[::-1])\n",
    "    if match:\n",
    "        position = len(text) - match.start() - 1\n",
    "        return position\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_yield_from_title(title):\n",
    "    \"\"\"\n",
    "    Extract yield value from title.\n",
    "    \"\"\"\n",
    "    if \"bu\" in title and \"yie\" in title:\n",
    "        value = title.split('bu')[0].split(',')[-1]\n",
    "        if '\"' in value:\n",
    "            value = value.split('\"')[-1].strip()\n",
    "        else:\n",
    "            value = value.split(' ')[-1].strip()\n",
    "        return value\n",
    "    return -1\n",
    "\n",
    "def extract_product_from_title(title):\n",
    "    \"\"\"\n",
    "    Extract product from title.\n",
    "    \"\"\"\n",
    "    if not('acre ' in title):\n",
    "        title = title.replace('acre', 'acre ')\n",
    "    if title.startswith(\"---------\"):\n",
    "        product = title.split('acre ')[1].split(',')[0]\n",
    "    else:\n",
    "        product = title.split('acre ')[1].split(',')[0]\n",
    "    return product\n",
    "\n",
    "def process_pdf_batch(pdf_links, year_from_url=False):\n",
    "    \"\"\"\n",
    "    Process a batch of PDF links and extract data into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        pdf_links (list): List of PDF URLs.\n",
    "        year_from_url (bool): If True, extract year from URL; else from title.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Extracted data.\n",
    "    \"\"\"\n",
    "    DATA = pd.DataFrame([])\n",
    "    for pdf_link in pdf_links:\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(delete=True, suffix=\".pdf\") as temp_file:\n",
    "                response = requests.get(pdf_link, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                temp_file.write(response.content)\n",
    "                pdf_reader = PdfReader(temp_file.name)\n",
    "            logger.info(f'Read! {pdf_link}')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Error downloading {pdf_link}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {pdf_link}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for page in pdf_reader.pages:\n",
    "            text = page.extract_text().strip()\n",
    "            text = strip_characters(text, \"_\")\n",
    "            if len(text) > 30:\n",
    "                init_ = text.replace(' ', '')\n",
    "                if ('Tab' in init_) and ('BSum' in init_):\n",
    "                    final = init_\n",
    "                    clean = final.split('ITEM')[0].replace(' ', '').strip().split(\"\\n\")\n",
    "                    title = ' '.join(clean)\n",
    "\n",
    "                    # Extract year\n",
    "                    if year_from_url:\n",
    "                        year = \"20\" + pdf_link.split('docs/')[-1].split('/')[0]\n",
    "                    else:\n",
    "                        if title.startswith(\"---------\"):\n",
    "                            year = title.replace(' ', '').replace('_', '')[-4:]\n",
    "                        else:\n",
    "                            year = title[-4:]\n",
    "\n",
    "                    # Extract yield\n",
    "                    yield_value = extract_yield_from_title(title)\n",
    "                    yield_ = ['Yield', 'bu', yield_value]\n",
    "\n",
    "                    # Extract product\n",
    "                    product = extract_product_from_title(title)\n",
    "\n",
    "                    irrigation = \"Irrigated\" if \"Irrig\" in title else \"Not available\"\n",
    "                    tilled = \"Tilled\" if \"till\" in title else \"Not available\"\n",
    "\n",
    "                    try:\n",
    "                        table = final.split('DIRECTEXPENSES\\n')[1]\n",
    "                    except IndexError:\n",
    "                        try:\n",
    "                            table = final.split('DIRECTEXPENSES')[1]\n",
    "                        except IndexError:\n",
    "                            logger.warning(f\"No DIRECTEXPENSES section in {pdf_link}\")\n",
    "                            continue\n",
    "\n",
    "                    output = \"ITEM\\tUNIT\\tAMOUNT\\n\"\n",
    "                    lines = []\n",
    "                    for line in table.split('\\n'):\n",
    "                        if len(line) < 40:\n",
    "                            lines.append(line)\n",
    "                        else:\n",
    "                            nested_list = re.sub(r'(\\d)(?=[A-Z])', r'\\1\\n', line)\n",
    "                            lines += nested_list.split(\"\\n\")\n",
    "\n",
    "                    for line in lines:\n",
    "                        if \"RETURN\" in line:\n",
    "                            break\n",
    "                        if not('TOTAL' in line):\n",
    "                            pos = last_uppercase_position(line)\n",
    "                            if pos is None:\n",
    "                                continue\n",
    "                            item = line[:pos+1]\n",
    "                            line = line.replace('gal', 'gal ') if \"gal\" in line else line\n",
    "                            unit = line[pos+1:pos+5] if line.count('.') <= 3 else \"acre\"\n",
    "                            amount = line[line.rfind('.', 0, line.rfind('.') - 1)+5:]\n",
    "                            output += f\"{item}\\t{unit}\\t{amount}\\n\"\n",
    "\n",
    "                    df = pd.read_csv(StringIO(output), sep='\\t')\n",
    "                    df.loc[len(df)] = yield_\n",
    "                    df = df.assign(Year=year, Product=product, Location='Mississippi', Currency=\"USD\", Irrigation=irrigation, Tilled=tilled)\n",
    "                    DATA = pd.concat([DATA, df], ignore_index=True)\n",
    "    \n",
    "    # Clean data\n",
    "    DATA['AMOUNT'] = DATA['AMOUNT'].astype(str).str.replace(' ', '').str.replace('-', '').astype(float)\n",
    "    DATA['Year'] = DATA['Year'].astype(str).str.replace('ppi,', '2023').astype(int)\n",
    "    return DATA\n",
    "\n",
    "# Main script\n",
    "url = \"https://www.agecon.msstate.edu/whatwedo/budgets/archive.php\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "recent_years = [str(datetime.now().year)[-2:], str(datetime.now().year + 1)[-2:]]\n",
    "\n",
    "a_tags = soup.find_all('a')\n",
    "all_links = []\n",
    "for tag in a_tags:\n",
    "    if 'docs' in tag['href'] and 'pdf' in tag['href']:\n",
    "        link = url.split('archive')[0] + tag['href']\n",
    "        if \"budgets//whatwedo\" in link:\n",
    "            link = '//'.join(link.split('//')[:2]) + link.split('budgets')[-1]\n",
    "        all_links.append(link)\n",
    "\n",
    "# Filter for recent years\n",
    "recent_links = [link for link in all_links if link.split('docs/')[-1].split('/')[0] in recent_years]\n",
    "\n",
    "# Process in batches\n",
    "batch_size = 35\n",
    "for i, start in enumerate(range(0, len(recent_links), batch_size)):\n",
    "    batch = recent_links[start:start + batch_size]\n",
    "    year_from_url = i > 0  # First batch uses title, others use URL\n",
    "    data = process_pdf_batch(batch, year_from_url=year_from_url)\n",
    "    data.to_csv(f\"part{i+1}.csv\", index=False)\n",
    "    logger.info(f\"Processed part {i+1}, unique items: {data['ITEM'].unique() if not data.empty else 'None'}\")\n",
    "    logger.info(f\"Unique years: {data['Year'].unique() if not data.empty else 'None'}\")\n",
    "    logger.info(f\"Unique products: {data['Product'].unique() if not data.empty else 'None'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
